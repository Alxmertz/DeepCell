{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic segmentation\n",
    "\n",
    "This ipython notebook recreates the semantic segmentation figures. First we need to load some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tifffile.py:156: UserWarning: failed to import the optional _tifffile C extension module.\n",
      "Loading of some compressed images will be slow.\n",
      "Tifffile.c can be obtained at http://www.lfd.uci.edu/~gohlke/\n",
      "  \"failed to import the optional _tifffile C extension module.\\n\"\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import tifffile as tiff\n",
    "from keras.backend.common import _UID_PREFIXES\n",
    "from skimage.measure import label, regionprops\n",
    "from cnn_functions import nikon_getfiles, get_image, run_models_on_directory, get_image_sizes, segment_nuclei, segment_cytoplasm, dice_jaccard_indices\n",
    "from model_zoo import sparse_bn_feature_net_61x61 as cyto_fn\n",
    "from model_zoo import sparse_bn_feature_net_61x61 as nuclear_fn\n",
    "from skimage import segmentation\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets process the images with our trained conv-nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1 of 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load data\n",
    "\"\"\"\n",
    "direc_name = '/Users/nicolasquach/sherlock_home/DeepCell2/testing_data/MCF10A_3T3/set1'\n",
    "data_location = os.path.join(direc_name, 'RawImages')\n",
    "cyto_location = os.path.join(direc_name, 'Cytoplasm')\n",
    "nuclear_location = os.path.join(direc_name, 'Nuclear')\n",
    "mask_location = os.path.join(direc_name, 'Masks')\n",
    "\n",
    "cyto_channel_names = ['Phase', 'DAPI']\n",
    "nuclear_channel_names = ['DAPI']\n",
    "\n",
    "trained_network_cyto_directory = \"/Users/nicolasquach/sherlock_home/DeepCell2/trained_networks/MCF10A_3T3_semantic\"\n",
    "trained_network_nuclear_directory = \"/Users/nicolasquach/sherlock_home/DeepCell2/trained_networks/Nuclear\"\n",
    "\n",
    "cyto_prefix = \"2016-07-28_MCF10A_3T3_all_semantic_61x61_bn_feature_net_61x61_semantic_all_\"\n",
    "nuclear_prefix = \"2016-07-12_nuclei_all_61x61_bn_feature_net_61x61_\"\n",
    "\n",
    "win_cyto = 30\n",
    "win_nuclear = 30\n",
    "\n",
    "image_size_x, image_size_y = get_image_sizes(data_location, nuclear_channel_names)\n",
    "\n",
    "\"\"\"\n",
    "Define model\n",
    "\"\"\"\n",
    "\n",
    "list_of_cyto_weights = []\n",
    "for j in xrange(5):\n",
    "\tcyto_weights = os.path.join(trained_network_cyto_directory,  cyto_prefix + str(j) + \".h5\")\n",
    "\tlist_of_cyto_weights += [cyto_weights]\n",
    "\n",
    "list_of_nuclear_weights = []\n",
    "for j in xrange(5):\n",
    "\tnuclear_weights = os.path.join(trained_network_nuclear_directory,  nuclear_prefix + str(j) + \".h5\")\n",
    "\tlist_of_nuclear_weights += [nuclear_weights]\n",
    "\n",
    "\"\"\"\n",
    "Run model on directory\n",
    "\"\"\"\n",
    "\n",
    "cytoplasm_predictions = run_models_on_directory(data_location, cyto_channel_names, cyto_location, n_features = 4, model_fn = cyto_fn, \n",
    "\tlist_of_weights = list_of_cyto_weights, image_size_x = image_size_x, image_size_y = image_size_y, \n",
    "\twin_x = win_cyto, win_y = win_cyto, std = False, split = False)\n",
    "\n",
    "nuclear_predictions = run_models_on_directory(data_location, nuclear_channel_names, nuclear_location, model_fn = nuclear_fn, \n",
    "\tlist_of_weights = list_of_nuclear_weights, image_size_x = image_size_x, image_size_y = image_size_y, \n",
    "\twin_x = win_nuclear, win_y = win_nuclear, std = False, split = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nuclear_masks = segment_nuclei(img = nuclear_predictions, color_image = True, load_from_direc = None, mask_location = mask_location, threshold = 0.75, area_threshold = 100, solidity_threshold = 0.75, eccentricity_threshold = 1)\n",
    "cyto_combined_predictions = np.zeros(cytoplasm_predictions.shape)\n",
    "cyto_combined_predictions[:,1,:,:] = cytoplasm_predictions[:,1,:,:] + cytoplasm_predictions[:,2,:,:]\n",
    "cytoplasm_masks = segment_cytoplasm(img = cyto_combined_predictions, load_from_direc = None, color_image = True, nuclear_masks = nuclear_masks, mask_location = mask_location, smoothing = 1, num_iters = 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets color the segmentation mask by our cell type prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute cell categorization prediction for each cell\n",
    "interior1 = cytoplasm_predictions[0,1,:,:]\n",
    "interior2 = cytoplasm_predictions[0,2,:,:]\n",
    "seg = label(cytoplasm_masks[0,:,:])\n",
    "num_of_cells = np.amax(seg) \n",
    "prediction = np.zeros(interior1.shape, dtype = np.float32)\n",
    "prediction_color = np.zeros((interior1.shape[0],interior1.shape[1],3), dtype = np.float32)\n",
    "\n",
    "bound = segmentation.find_boundaries(seg)\n",
    "for cell_no in xrange(1,num_of_cells):\n",
    "\tclass_1_pred = interior1[seg == cell_no]\n",
    "\tclass_2_pred = interior2[seg == cell_no]\n",
    "\tclass_1_score = np.sum(class_1_pred)/(np.sum(class_1_pred) + np.sum(class_2_pred))\n",
    "\tclass_2_score = np.sum(class_2_pred)/(np.sum(class_1_pred) + np.sum(class_2_pred))\n",
    "\n",
    "\tprediction[seg == cell_no] = class_2_score\n",
    "\tprediction_color[seg == cell_no,0] = plt.cm.coolwarm(class_2_score)[0]\n",
    "\tprediction_color[seg == cell_no,1] = plt.cm.coolwarm(class_2_score)[1]\n",
    "\tprediction_color[seg == cell_no,2] = plt.cm.coolwarm(class_2_score)[2]\n",
    "\n",
    "prediction_color[bound,0] = 0\n",
    "prediction_color[bound,1] = 0\n",
    "prediction_color[bound,2] = 0\n",
    "cnnout_name = os.path.join(mask_location, 'segmentation_rgb_new.tif')\n",
    "scipy.misc.imsave(cnnout_name,np.float16(prediction_color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets quantify the classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n",
      "84 13\n",
      "196 0\n",
      "[86.597938144329902, 100.0]\n"
     ]
    }
   ],
   "source": [
    "other_location = os.path.join(direc_name, 'OtherChannels')\n",
    "\n",
    "imglist_class1 = nikon_getfiles(other_location,'CFP')\n",
    "imglist_class2 = nikon_getfiles(other_location,'Far-red')\n",
    "\n",
    "class1_name = os.path.join(other_location, imglist_class1[0])\n",
    "class2_name = os.path.join(other_location, imglist_class2[0])\n",
    "\n",
    "nuclear_class1 = get_image(class1_name) \n",
    "nuclear_class2 = get_image(class2_name)\n",
    "\n",
    "nuclear_class1 -= np.mean(nuclear_class1)\n",
    "nuclear_class2 -= np.mean(nuclear_class2)\n",
    "\n",
    "truth = np.zeros(interior1.shape, dtype = np.float32)\n",
    "\n",
    "correct_class1 = 0\n",
    "incorrect_class1 = 0\n",
    "\n",
    "correct_class2 = 0\n",
    "incorrect_class2 = 0\n",
    "\n",
    "for cell_no in xrange(1,num_of_cells):\n",
    "\tactual_class_1_pred = nuclear_class1[seg == cell_no]\n",
    "\tactual_class_2_pred = nuclear_class2[seg == cell_no]\n",
    "\n",
    "\tif np.sum(actual_class_1_pred) > np.sum(actual_class_2_pred):\n",
    "\t\ttruth[seg == cell_no] = 1\n",
    "\telif np.sum(actual_class_1_pred) < np.sum(actual_class_2_pred):\n",
    "\t\ttruth[seg == cell_no] = 2\n",
    "\n",
    "print num_of_cells\n",
    "correct_scores = []\n",
    "incorrect_scores = []\n",
    "\n",
    "for cell_no in xrange(1,num_of_cells):\n",
    "\tprediction_value = np.float32(np.mean(prediction[seg == cell_no]) > 0.5) + 1\n",
    "\ttruth_value = np.mean(truth[seg == cell_no])\n",
    "\n",
    "\tif truth_value == 1:\n",
    "\t\tif truth_value == prediction_value:\n",
    "\t\t\tcorrect_class1 += 1\n",
    "\t\t\tcorrect_scores += [1-np.mean(prediction[seg == cell_no])]\n",
    "\t\telif truth_value != prediction_value:\n",
    "\t\t\tincorrect_class1 += 1\n",
    "\t\t\tincorrect_scores += [1-np.mean(prediction[seg == cell_no])]\n",
    "\n",
    "\n",
    "\tif truth_value == 2:\n",
    "\t\tif truth_value == prediction_value:\n",
    "\t\t\tcorrect_class2 += 1\n",
    "\t\t\tcorrect_scores += [np.mean(prediction[seg == cell_no])]\n",
    "\n",
    "\t\telif truth_value != prediction_value:\n",
    "\t\t\tincorrect_class2 += 1\n",
    "\t\t\tincorrect_scores += [np.mean(prediction[seg == cell_no])]\n",
    "\n",
    "\n",
    "print correct_class1, incorrect_class1\n",
    "print correct_class2, incorrect_class2\n",
    "\n",
    "correct_class1 = np.float32(correct_class1)\n",
    "correct_class2 = np.float32(correct_class2)\n",
    "\n",
    "percent_correct1 = correct_class1/(correct_class1 + incorrect_class1)*100\n",
    "percent_correct2 = correct_class2/(correct_class2 +incorrect_class2)*100\n",
    "percent_correct = [percent_correct1, percent_correct2]\n",
    "print percent_correct\n",
    "\n",
    "incorrect_hist = plt.hist(incorrect_scores, bins = 20, label = 'Incorrectly classified cells', color = (np.float(204)/255, np.float(121)/255, np.float(167)/255))\n",
    "correct_hist = plt.hist(correct_scores, bins = 20, label = 'Correctly classified cells', color = (np.float(0)/255, np.float(114)/255, np.float(178)/255))\n",
    "\n",
    "plt.xlabel(r'Cellular classification score', fontsize = 16)\n",
    "plt.ylabel(r'Number of cells', fontsize = 16)\n",
    "# plt.title('', y = 1.03, fontsize = 20)\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.xticks([0,0.5,1],  fontsize = 16)\n",
    "plt.ylim([0, 150])\n",
    "plt.yticks([0,50,100,150],  fontsize = 16)\n",
    "plt.legend(loc = 2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"class_scores.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
